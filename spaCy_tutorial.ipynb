{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "spaCy_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjc89/ML_exercises/blob/master/spaCy_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaAJrIrADDWI",
        "colab_type": "code",
        "colab": {},
        "outputId": "eae395ea-92eb-44a9-a294-41079185ada5"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/ihardege/Documents\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whTt-w7SDDWR",
        "colab_type": "code",
        "colab": {},
        "outputId": "79363636-c59f-4cb7-d0ce-45be7fd5a002"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Hello, world. Here are two sentences.\")\n",
        "print([t.text for t in doc])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', ',', 'world', '.', 'Here', 'are', 'two', 'sentences', '.']\n",
            "['Ich', 'bin', 'ein', 'Berliner', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvE7sitWDDWV",
        "colab_type": "code",
        "colab": {},
        "outputId": "775e2344-eeca-4886-c396-ad483dcb1e55"
      },
      "source": [
        "nlp_de = spacy.load(\"de_core_news_sm\")\n",
        "doc_de = nlp_de(\"Ich bin ein Berliner.\")\n",
        "print([t.text for t in doc_de])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ich', 'bin', 'ein', 'Berliner', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqSR63CjDDWb",
        "colab_type": "text"
      },
      "source": [
        "## Get tokens noun chunks and sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_zTYBdYDDWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Peach emoji is where it has always been. Peach is the superior \"\n",
        "          \"emoji. It's outranking eggplant üçë \")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaT1r68KDDWk",
        "colab_type": "code",
        "colab": {},
        "outputId": "7a1c2d8c-4b3d-4eea-a467-6e1528ce4be5"
      },
      "source": [
        "print(doc[0].text)          # 'Peach'\n",
        "print(doc[1].text)          # 'emoji'\n",
        "print(doc[-1].text)         # 'üçë'\n",
        "print(doc[17:19].text)      # 'outranking eggplant'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peach\n",
            "emoji\n",
            "üçë\n",
            "outranking eggplant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trN9a2mjDDWo",
        "colab_type": "code",
        "colab": {},
        "outputId": "04cf2b32-e2ef-4e44-b1ff-000286aad9fb"
      },
      "source": [
        "noun_chunks = list(doc.noun_chunks)\n",
        "print(noun_chunks[0].text)  # 'Peach emoji'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peach emoji\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v_n79g4DDWt",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb898e38-8088-483f-b6b3-17a2480efde5"
      },
      "source": [
        "sentences = list(doc.sents)\n",
        "assert len(sentences) == 3\n",
        "print(sentences[1].text)    # 'Peach is the superior emoji.'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peach is the superior emoji.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uEEWroGDDWx",
        "colab_type": "text"
      },
      "source": [
        "## Get part of speech flags and tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwSq8VgdDDWz",
        "colab_type": "code",
        "colab": {},
        "outputId": "73bc7adb-fd4e-45d1-d512-e1009e0c3433"
      },
      "source": [
        "import spacy \n",
        "#https://spacy.io/usage/spacy-101 #lightning-tour-pos-tags\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "apple = doc[0]\n",
        "print(\"Fine-grained POS tag\", apple.pos_, apple.pos)\n",
        "print(\"Coarse-grained POS tag\", apple.tag_, apple.tag)\n",
        "print(\"Word shape\", apple.shape_, apple.shape)\n",
        "print(\"Alphabetic characters?\", apple.is_alpha)\n",
        "print(\"Punctuation mark?\", apple.is_punct)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine-grained POS tag PROPN 96\n",
            "Coarse-grained POS tag NNP 15794550382381185553\n",
            "Word shape Xxxxx 16072095006890171862\n",
            "Alphabetic characters? True\n",
            "Punctuation mark? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dGla3eGDDW3",
        "colab_type": "code",
        "colab": {},
        "outputId": "5ddc2437-9e71-46c1-a821-2a631bc07633"
      },
      "source": [
        "billion = doc[10]\n",
        "print(\"Digit?\", billion.is_digit)\n",
        "print(\"Like a number?\", billion.like_num)\n",
        "print(\"Like an email address?\", billion.like_email)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Digit? False\n",
            "Like a number? True\n",
            "Like an email address? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZSfLiMDDW8",
        "colab_type": "text"
      },
      "source": [
        "## Use hash values for any string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BtqBXAKDDW9",
        "colab_type": "code",
        "colab": {},
        "outputId": "820622b8-3011-46e0-9509-29d80dc689e0"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I love coffee\")\n",
        "\n",
        "coffee_hash = nlp.vocab.strings[\"coffee\"]  # 3197928453018144401\n",
        "coffee_text = nlp.vocab.strings[coffee_hash]  # 'coffee'\n",
        "print(coffee_hash, coffee_text)\n",
        "print(doc[2].orth, coffee_hash)  # 3197928453018144401\n",
        "print(doc[2].text, coffee_text)  # 'coffee'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3197928453018144401 coffee\n",
            "3197928453018144401 3197928453018144401\n",
            "coffee coffee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuvlIuwFDDXB",
        "colab_type": "code",
        "colab": {},
        "outputId": "560d75ea-8d4b-41d7-b8fd-db36b25603fc"
      },
      "source": [
        "\n",
        "beer_hash = doc.vocab.strings.add(\"beer\")  # 3073001599257881079\n",
        "beer_text = doc.vocab.strings[beer_hash]  # 'beer'\n",
        "print(beer_hash, beer_text)\n",
        "\n",
        "unicorn_hash = doc.vocab.strings.add(\"ü¶Ñ\")  # 18234233413267120783\n",
        "unicorn_text = doc.vocab.strings[unicorn_hash]  # 'ü¶Ñ'\n",
        "print(unicorn_hash, unicorn_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3073001599257881079 beer\n",
            "18234233413267120783 ü¶Ñ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmDzuutyDDXG",
        "colab_type": "text"
      },
      "source": [
        "## Recognise and update named entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR8XPmCoDDXI",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a5b5df6-1258-4a80-876a-b7aa1ee4b4a2"
      },
      "source": [
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"San Francisco considers banning sidewalk delivery robots\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "\n",
        "doc = nlp(\"FB is hiring a new VP of global policy\")\n",
        "doc.ents = [Span(doc, 0, 1, label=\"ORG\")]\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "San Francisco 0 13 GPE\n",
            "FB 0 2 ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL9P7oaODDXN",
        "colab_type": "text"
      },
      "source": [
        "## Train and update neural network models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4X07qo3DDXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "train_data = [(\"Uber blew through $1 million\", {\"entities\": [(0, 4, \"ORG\")]})]\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    for i in range(10):\n",
        "        random.shuffle(train_data)\n",
        "        for text, annotations in train_data:\n",
        "            nlp.update([text], [annotations], sgd=optimizer)\n",
        "nlp.to_disk(\"./model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R3-OMXUDDXT",
        "colab_type": "code",
        "colab": {},
        "outputId": "9abf266a-ef60-4761-c017-181b82311b35"
      },
      "source": [
        "!ls ./model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meta.json \u001b[34mner\u001b[m\u001b[m       \u001b[34mparser\u001b[m\u001b[m    \u001b[34mtagger\u001b[m\u001b[m    tokenizer \u001b[34mvocab\u001b[m\u001b[m\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tqvvtUoDDXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open('./model/meta.json') as f:\n",
        "  data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRc-TtkBDDXb",
        "colab_type": "code",
        "colab": {},
        "outputId": "a7f79a2b-e5fd-4f08-c2ae-1a705c5c3872"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lang': 'en', 'name': 'core_web_sm', 'license': 'MIT', 'author': 'Explosion', 'url': 'https://explosion.ai', 'email': 'contact@explosion.ai', 'description': 'English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities.', 'sources': [{'name': 'OntoNotes 5', 'url': 'https://catalog.ldc.upenn.edu/LDC2013T19', 'license': 'commercial (licensed by Explosion)'}], 'pipeline': ['tagger', 'parser', 'ner'], 'version': '2.2.5', 'spacy_version': '>=2.2.2', 'parent_package': 'spacy', 'accuracy': {'las': 89.7130416495, 'uas': 91.6218131967, 'token_acc': 99.7579930934, 'tags_acc': 97.0493515238, 'ents_f': 85.5515654809, 'ents_p': 85.8937524646, 'ents_r': 85.212094115}, 'speed': {'cpu': 7045.5080732798, 'gpu': None, 'nwords': 291314}, 'labels': {'tagger': ['$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'AFX', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'XX', '_SP', '``'], 'parser': ['ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', 'attr', 'aux', 'auxpass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'csubj', 'csubjpass', 'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', 'meta', 'neg', 'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis', 'pcomp', 'pobj', 'poss', 'preconj', 'predet', 'prep', 'prt', 'punct', 'quantmod', 'relcl', 'xcomp'], 'ner': ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']}, 'vectors': {'width': 0, 'vectors': 0, 'keys': 0, 'name': 'spacy_pretrained_vectors'}, 'factories': {'tagger': 'tagger', 'parser': 'parser', 'ner': 'ner'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Koh6DAT1DDXe",
        "colab_type": "text"
      },
      "source": [
        "## Visualise a dependency parse and named entities in browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH2tejhmDDXf",
        "colab_type": "code",
        "colab": {},
        "outputId": "f9430ffd-023b-4e4a-a0d2-cac9f61c3155"
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc_dep = nlp(\"This is a sentence.\")\n",
        "displacy.serve(doc_dep, style=\"dep\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Applications/anaconda3/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"07d89bd59de94866a783bea979ec074c-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-07d89bd59de94866a783bea979ec074c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-07d89bd59de94866a783bea979ec074c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-07d89bd59de94866a783bea979ec074c-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-07d89bd59de94866a783bea979ec074c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-07d89bd59de94866a783bea979ec074c-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-07d89bd59de94866a783bea979ec074c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>\n",
              "</figure>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpbU7qU8DDXj",
        "colab_type": "code",
        "colab": {},
        "outputId": "9610cdc0-a58a-4153-969e-1582df3790f6"
      },
      "source": [
        "doc_ent = nlp(\"When Sebastian Thrun started working on self-driving cars at Google \"\n",
        "              \"in 2007, few people outside of the company took him seriously.\")\n",
        "displacy.serve(doc_ent, style=\"ent\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Applications/anaconda3/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sebastian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " Thrun started working on self-driving cars at \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2007\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", few people outside of the company took him seriously.</div>\n",
              "</figure>\n",
              "</body>\n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Q6NNzqDDXm",
        "colab_type": "text"
      },
      "source": [
        "## Get word vectors and similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdXlDE8BDDXo",
        "colab_type": "code",
        "colab": {},
        "outputId": "180861b8-9efc-4aea-d733-578f5655e4a8"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "doc = nlp(\"Apple and banana are similar. Pasta and hippo aren't.\")\n",
        "\n",
        "apple = doc[0]\n",
        "banana = doc[2]\n",
        "pasta = doc[6]\n",
        "hippo = doc[8]\n",
        "\n",
        "print(\"apple <-> banana\", apple.similarity(banana))\n",
        "print(\"pasta <-> hippo\", pasta.similarity(hippo))\n",
        "print(apple.has_vector, banana.has_vector, pasta.has_vector, hippo.has_vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-992968dc0589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_md\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Apple and banana are similar. Pasta and hippo aren't.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mapple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbanana\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Applications/anaconda3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Applications/anaconda3/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFFL0J7mDDXv",
        "colab_type": "text"
      },
      "source": [
        "## Simple and efficient serialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IynwYHXjDDXw",
        "colab_type": "code",
        "colab": {},
        "outputId": "cdf0f8a1-121a-4273-9b8c-a0b72187e1b6"
      },
      "source": [
        "from spacy.tokens import Doc\n",
        "from spacy.vocab import Vocab\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "customer_feedback = open(\"customer_feedback_627.txt\").read()\n",
        "doc = nlp(customer_feedback)\n",
        "doc.to_disk(\"/tmp/customer_feedback_627.bin\")\n",
        "\n",
        "new_doc = Doc(Vocab()).from_disk(\"/tmp/customer_feedback_627.bin\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'customer_feedback_627.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-96ccb60ae536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcustomer_feedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"customer_feedback_627.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/customer_feedback_627.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'customer_feedback_627.txt'"
          ]
        }
      ]
    }
  ]
}